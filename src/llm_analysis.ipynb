{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyric LLM RAG Project - Harshini Raju\n",
    "**PART 2 - Process Data and Identify Emotion for songs using Langchain and HuggingFaceHub Chat Model**\n",
    "<br><br>- Utilise Langchain and HuggingFaceHub Chat models to understand the emotion for the translation of each song.<br>- Save the identifies emotions for each line in lyrics and identify most common emotion for each song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  nlpcloud\n",
    "%pip install -q huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "from langchain import PromptTemplate\n",
    "import json\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "# Download the Punkt tokenizer for sentence splitting (only need to do this once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk.corpus import words\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Key for HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"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\"\n",
    "HUGGINGFACE_API_KEY = os.environ[\"HUGGINGFACE_API_KEY\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the input data- JSON of song names and their lyric (translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON file\n",
    "with open('song_data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise the prompt for the Langchain chat model to utilise for identifying emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template='''You analyze the emotions of the text provided. Classify the emotions to happy, sad, love, anger, depressed, fun, comfort, motivation, confident\n",
    "{text}\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(template = template,input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize Hub LLM\n",
    "hub_llm = HuggingFaceHub(\n",
    "        repo_id='google/flan-t5-xxl',\n",
    "    huggingfacehub_api_token = HUGGINGFACE_API_KEY,\n",
    "    model_kwargs={'temperature':0.8,\n",
    "                  'max_length':2048}\n",
    ")\n",
    "\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=hub_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to pre-process text\n",
    "- splitting sentences to tokenize the lyrics translation\n",
    "- clean the text to remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_english(text):\n",
    "    # Define a regular expression pattern to match non-English characters\n",
    "    non_english_pattern = re.compile(r'[^\\x00-\\x7F]+')\n",
    "\n",
    "    # Use the pattern to substitute non-English characters with an empty string\n",
    "    cleaned_text = non_english_pattern.sub('', text)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to idenitfy the most common emotino in each song based on lyric translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_with_maximum_count(word_list):\n",
    "    # Convert the words to lowercase for case-insensitive counting\n",
    "    lowercased_words = [word.lower() for word in word_list]\n",
    "    \n",
    "    # Use Counter to count occurrences of each word\n",
    "    word_counts = Counter(lowercased_words)\n",
    "    \n",
    "    # Find the word with the maximum count\n",
    "    max_word = max(word_counts, key=word_counts.get)\n",
    "    \n",
    "    return max_word, word_counts[max_word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_emotion = {}\n",
    "emotions1 = {}\n",
    "lyric_emotion = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Emotions in each line and find the most common emotion per song\n",
    "<br> Two JSONs are populated here:\n",
    "- song_emotion => Has the most common emotion for a song (After calculating based on emotion for each line)\n",
    "- lyric_emotion => JSON that stores the emotion identified in each line of the song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voice\n",
      "do-you\n",
      "awakening\n",
      "monster\n",
      "%eb%b2%84%eb%a0%a4-throw-away\n",
      "joke\n",
      "god-rap\n",
      "rush-feat-krizz-kaliko\n",
      "life\n",
      "adrift\n",
      "i-believe\n"
     ]
    }
   ],
   "source": [
    "for index, (song, value) in enumerate(data.items()):\n",
    "    if index > 0:  # Had to manually manage the iteration to accomodate for API Rate Limits \n",
    "        print(song)\n",
    "        result_sentences = split_into_sentences(data[song])\n",
    "\n",
    "        # Print the result\n",
    "        for sentence in result_sentences:\n",
    "            sentence_clean =remove_non_english(sentence)\n",
    "\n",
    "            if len(sentence_clean)>=1024:\n",
    "                short_sent = sentence_clean.split(\"\\n\")\n",
    "                for s in short_sent:\n",
    "                    emotions1[s] =llm_chain.run(s)\n",
    "            else:\n",
    "                emotions1[sentence_clean]= llm_chain.run(sentence_clean)\n",
    "        max_word, max_count = word_with_maximum_count(emotions1)\n",
    "        song_emotion[song] = max_word\n",
    "        print(f\"The word with the maximum count for {song} is '{max_word}' with count: {max_count}\")\n",
    "        lyric_emotion[song]=emotions1\n",
    "        time.sleep(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save both the JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "file_path = 'song_emotion.json'\n",
    "\n",
    "# Load existing data from the file if it exists\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "        existing_data = json.load(json_file)\n",
    "except FileNotFoundError:\n",
    "    # If the file doesn't exist yet, initialize with an empty dictionary\n",
    "    existing_data = {}\n",
    "\n",
    "# Update the existing data with the new data\n",
    "existing_data.update(song_emotion)\n",
    "\n",
    "# Save the updated dictionary as a JSON file\n",
    "with open(file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(existing_data, json_file, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "file_path = 'lyric_emotion.json'\n",
    "\n",
    "# Load existing data from the file if it exists\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "        existing_data = json.load(json_file)\n",
    "except FileNotFoundError:\n",
    "    # If the file doesn't exist yet, initialize with an empty dictionary\n",
    "    existing_data = {}\n",
    "\n",
    "# Update the existing data with the new data\n",
    "existing_data.update(lyric_emotion)\n",
    "\n",
    "# Save the updated dictionary as a JSON file\n",
    "with open(file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(existing_data, json_file, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "# File path\n",
    "file_path = 'lyric_emotion.json'\n",
    "\n",
    "# Load existing data from the file if it exists\n",
    "with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "    existing_data = json.load(json_file)\n",
    "    print(len(existing_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the JSON files as CSV for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_json_to_csv(filename):\n",
    "    # Load the JSON data\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Create empty lists to store song names and emotions\n",
    "    song_names = []\n",
    "    emotions = []\n",
    "\n",
    "    # Iterate over the JSON data and extract song names and emotions\n",
    "    for song_name, emotion in data.items():\n",
    "        song_names.append(song_name)\n",
    "        emotions.append(emotion)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Song Name': song_names,\n",
    "        'Emotion': emotions\n",
    "    })\n",
    "\n",
    "    # Construct CSV filename\n",
    "    csv_filename = filename.split(\".\")[0] + \".csv\"\n",
    "\n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Song Name    Emotion\n",
      "0         black-swan  depressed\n",
      "1            my-time  depressed\n",
      "2  louder-than-bombs  depressed\n",
      "3                ugh      anger\n",
      "4        inner-child      happy\n",
      "         Song Name Emotion\n",
      "count          212     212\n",
      "unique         212      11\n",
      "top     black-swan    love\n",
      "freq             1      48\n"
     ]
    }
   ],
   "source": [
    "df_song = song_json_to_csv(\"song_emotion.json\")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_song.head())\n",
    "print(df_song.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyric_json_to_csv(filename):\n",
    "    # Load the JSON data\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Create empty lists to store song names, lyric lines, and emotions\n",
    "    song_names = []\n",
    "    lyric_lines = []\n",
    "    emotions = []\n",
    "\n",
    "    # Iterate over the JSON data and extract song names, lyric lines, and emotions\n",
    "    for song_name, lines in data.items():\n",
    "        for line, emotion in lines.items():\n",
    "            song_names.append(song_name)\n",
    "            lyric_lines.append(line)\n",
    "            emotions.append(emotion)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Song Name': song_names,\n",
    "        'Lyric Line': lyric_lines,\n",
    "        'Emotion': emotions\n",
    "    })\n",
    "\n",
    "    csv_filename = filename.split(\".\")[0] + \".csv\"\n",
    "\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Song Name                                         Lyric Line     Emotion\n",
      "0  born-singer   Original Track: Born Sinner byJ.Cole\\nLyrics ...  motivation\n",
      "1  born-singer                      Im a born singer    (I swear)   confident\n",
      "2  born-singer  Im a born singer, a bit belated confession (I ...         fun\n",
      "3  born-singer  A mirage that used to be ever so far awayis in...  motivation\n",
      "4  born-singer  Im a born singer,perhaps a bit early confessio...   confident\n",
      "          Song Name                                   Lyric Line Emotion\n",
      "count        201738                                       201738  201738\n",
      "unique          209                                         5533     110\n",
      "top     born-singer  Please click here for inquiries & feedback!    love\n",
      "freq           2255                                          209   45574\n"
     ]
    }
   ],
   "source": [
    "df = lyric_json_to_csv(\"lyric_emotion.json\")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n",
    "print(df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
